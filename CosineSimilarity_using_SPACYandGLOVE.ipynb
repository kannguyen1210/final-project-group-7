{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CosineSimilarity_using SPACYandGLOVE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kannguyen1210/final-project-group-7/blob/Svenja/CosineSimilarity_using_SPACYandGLOVE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g__7UCCvyiFO",
        "outputId": "a6f80423-a19c-43ab-f5cc-3ba2f3307d66"
      },
      "source": [
        "#NEED TO RUN THIS CELL FIRST AND THEN RESTART THE RUNTIME (WONT BE ABLE TO USE THE \"LARGE\" VERSION OF THEIR REPOSITORY WITHOUT A RESTART)\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180944 sha256=adc83583778303ae470c8009ce13d1bfc360504140ce36eabe1f430a0b271ceb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0eptk0km/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_8BYZtOyja5"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaDp2gQBw_0M",
        "outputId": "8f0b17df-ae20-46f8-c2de-2681698d80a4"
      },
      "source": [
        "#Lets see the words inside the largest Spacy model\n",
        "list(nlp.vocab.strings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"\"',\n",
              " '#',\n",
              " '$',\n",
              " \"''\",\n",
              " ',',\n",
              " '-LRB-',\n",
              " '-RRB-',\n",
              " '.',\n",
              " ':',\n",
              " 'ADD',\n",
              " 'AFX',\n",
              " 'BES',\n",
              " 'CC',\n",
              " 'CD',\n",
              " 'DT',\n",
              " 'EX',\n",
              " 'FW',\n",
              " 'GW',\n",
              " 'HVS',\n",
              " 'HYPH',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'JJR',\n",
              " 'JJS',\n",
              " 'LS',\n",
              " 'MD',\n",
              " 'NFP',\n",
              " 'NIL',\n",
              " 'NN',\n",
              " 'NNP',\n",
              " 'NNPS',\n",
              " 'NNS',\n",
              " 'PDT',\n",
              " 'PRP',\n",
              " 'PRP$',\n",
              " 'RB',\n",
              " 'RBR',\n",
              " 'RBS',\n",
              " 'RP',\n",
              " 'SP',\n",
              " 'TO',\n",
              " 'UH',\n",
              " 'VB',\n",
              " 'VBD',\n",
              " 'VBG',\n",
              " 'VBN',\n",
              " 'VBP',\n",
              " 'VBZ',\n",
              " 'WDT',\n",
              " 'WP',\n",
              " 'WP$',\n",
              " 'WRB',\n",
              " 'XX',\n",
              " '_SP',\n",
              " '``',\n",
              " 'that',\n",
              " 'if',\n",
              " 'as',\n",
              " 'because',\n",
              " 'while',\n",
              " 'since',\n",
              " 'like',\n",
              " 'so',\n",
              " 'than',\n",
              " 'whether',\n",
              " 'although',\n",
              " 'though',\n",
              " 'unless',\n",
              " 'once',\n",
              " 'cause',\n",
              " 'upon',\n",
              " 'till',\n",
              " 'whereas',\n",
              " 'whilst',\n",
              " 'except',\n",
              " 'despite',\n",
              " 'wether',\n",
              " 'but',\n",
              " 'becuse',\n",
              " 'whie',\n",
              " 'it',\n",
              " 'w/out',\n",
              " 'albeit',\n",
              " 'save',\n",
              " 'besides',\n",
              " 'becouse',\n",
              " 'coz',\n",
              " 'til',\n",
              " 'ask',\n",
              " \"i'd\",\n",
              " 'out',\n",
              " 'near',\n",
              " 'seince',\n",
              " 'tho',\n",
              " 'sice',\n",
              " 'will',\n",
              " 'That',\n",
              " 'If',\n",
              " 'As',\n",
              " 'Because',\n",
              " 'While',\n",
              " 'Since',\n",
              " 'Like',\n",
              " 'So',\n",
              " 'Than',\n",
              " 'Whether',\n",
              " 'Although',\n",
              " 'Though',\n",
              " 'Unless',\n",
              " 'Once',\n",
              " 'Cause',\n",
              " 'Upon',\n",
              " 'Till',\n",
              " 'Whereas',\n",
              " 'Whilst',\n",
              " 'Except',\n",
              " 'Despite',\n",
              " 'Wether',\n",
              " 'But',\n",
              " 'Becuse',\n",
              " 'Whie',\n",
              " 'It',\n",
              " 'W/Out',\n",
              " 'Albeit',\n",
              " 'Save',\n",
              " 'Besides',\n",
              " 'Becouse',\n",
              " 'Coz',\n",
              " 'Til',\n",
              " 'Ask',\n",
              " \"I'D\",\n",
              " 'Out',\n",
              " 'Near',\n",
              " 'Seince',\n",
              " 'Tho',\n",
              " 'Sice',\n",
              " 'Will',\n",
              " 'something',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'nothing',\n",
              " 'someone',\n",
              " 'everything',\n",
              " 'everyone',\n",
              " 'everybody',\n",
              " 'nobody',\n",
              " 'somebody',\n",
              " 'anybody',\n",
              " 'any1',\n",
              " 'Something',\n",
              " 'Anyone',\n",
              " 'Anything',\n",
              " 'Nothing',\n",
              " 'Someone',\n",
              " 'Everything',\n",
              " 'Everyone',\n",
              " 'Everybody',\n",
              " 'Nobody',\n",
              " 'Somebody',\n",
              " 'Anybody',\n",
              " 'Any1',\n",
              " '-PRON-',\n",
              " 'I',\n",
              " 'me',\n",
              " 'you',\n",
              " 'he',\n",
              " 'him',\n",
              " 'she',\n",
              " 'her',\n",
              " 'we',\n",
              " 'us',\n",
              " 'they',\n",
              " 'them',\n",
              " 'mine',\n",
              " 'his',\n",
              " 'hers',\n",
              " 'its',\n",
              " 'ours',\n",
              " 'yours',\n",
              " 'theirs',\n",
              " 'myself',\n",
              " 'yourself',\n",
              " 'himself',\n",
              " 'herself',\n",
              " 'itself',\n",
              " 'themself',\n",
              " 'ourselves',\n",
              " 'yourselves',\n",
              " 'themselves',\n",
              " 'Me',\n",
              " 'You',\n",
              " 'He',\n",
              " 'Him',\n",
              " 'She',\n",
              " 'Her',\n",
              " 'We',\n",
              " 'Us',\n",
              " 'They',\n",
              " 'Them',\n",
              " 'Mine',\n",
              " 'His',\n",
              " 'Hers',\n",
              " 'Its',\n",
              " 'Ours',\n",
              " 'Yours',\n",
              " 'Theirs',\n",
              " 'Myself',\n",
              " 'Yourself',\n",
              " 'Himself',\n",
              " 'Herself',\n",
              " 'Itself',\n",
              " 'Themself',\n",
              " 'Ourselves',\n",
              " 'Yourselves',\n",
              " 'Themselves',\n",
              " 'my',\n",
              " 'your',\n",
              " 'our',\n",
              " 'their',\n",
              " 'My',\n",
              " 'Your',\n",
              " 'Our',\n",
              " 'Their',\n",
              " 'not',\n",
              " \"n't\",\n",
              " 'nt',\n",
              " 'n’t',\n",
              " 'Not',\n",
              " \"N'T\",\n",
              " 'Nt',\n",
              " 'N’T',\n",
              " 'be',\n",
              " 'have',\n",
              " 'do',\n",
              " 'get',\n",
              " 'of',\n",
              " 'am',\n",
              " 'are',\n",
              " \"'ve\",\n",
              " 'Be',\n",
              " 'Have',\n",
              " 'Do',\n",
              " 'Get',\n",
              " 'Of',\n",
              " 'Am',\n",
              " 'Are',\n",
              " \"'Ve\",\n",
              " 'been',\n",
              " 'Been',\n",
              " 'being',\n",
              " 'Being',\n",
              " 'is',\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " 'has',\n",
              " 'does',\n",
              " 'Is',\n",
              " \"'Re\",\n",
              " \"'S\",\n",
              " 'Has',\n",
              " 'Does',\n",
              " \"'m\",\n",
              " \"'d\",\n",
              " \"'M\",\n",
              " \"'D\",\n",
              " 'was',\n",
              " 'were',\n",
              " 'did',\n",
              " 'had',\n",
              " 'Was',\n",
              " 'Were',\n",
              " 'Did',\n",
              " 'Had',\n",
              " '\\t',\n",
              " 'en',\n",
              " '\\n',\n",
              " ' ',\n",
              " '\")',\n",
              " '\"',\n",
              " \"'\",\n",
              " \"'Cause\",\n",
              " \"'cause\",\n",
              " 'use',\n",
              " \"'Xxxxx\",\n",
              " \"'Cos\",\n",
              " \"'cos\",\n",
              " 'Cos',\n",
              " \"'Xxx\",\n",
              " \"'Coz\",\n",
              " \"'coz\",\n",
              " \"'Cuz\",\n",
              " \"'cuz\",\n",
              " 'Cuz',\n",
              " \"'X\",\n",
              " \"'bout\",\n",
              " 'about',\n",
              " \"'xxxx\",\n",
              " 'cos',\n",
              " \"'xxx\",\n",
              " 'cuz',\n",
              " \"'x\",\n",
              " \"'em\",\n",
              " \"'xx\",\n",
              " \"'ll\",\n",
              " \"'nuff\",\n",
              " 'enough',\n",
              " 'uff',\n",
              " '(*_*)',\n",
              " '(',\n",
              " '_*)',\n",
              " '(-8',\n",
              " '(-d',\n",
              " '(-:',\n",
              " '(-;',\n",
              " '(-_-)',\n",
              " '_-)',\n",
              " '(._.)',\n",
              " '_.)',\n",
              " '(:',\n",
              " '(;',\n",
              " '(=',\n",
              " '(>_<)',\n",
              " '_<)',\n",
              " '(^_^)',\n",
              " '_^)',\n",
              " '(o:',\n",
              " '(x:',\n",
              " '(¬_¬)',\n",
              " '_¬)',\n",
              " '(ಠ_ಠ)',\n",
              " '_ಠ)',\n",
              " '(x_x)',\n",
              " '(╯°□°）╯︵┻━┻',\n",
              " '┻━┻',\n",
              " ')-:',\n",
              " ')',\n",
              " '):',\n",
              " '-_-',\n",
              " '-',\n",
              " '-__-',\n",
              " '__-',\n",
              " '._.',\n",
              " '0.0',\n",
              " '0',\n",
              " 'd.d',\n",
              " '0.o',\n",
              " 'd.x',\n",
              " '0_0',\n",
              " 'd_d',\n",
              " '0_o',\n",
              " 'd_x',\n",
              " '10',\n",
              " '1',\n",
              " 'dd',\n",
              " 'a.m.',\n",
              " 'a',\n",
              " '.m.',\n",
              " 'x.x.',\n",
              " 'xx',\n",
              " 'p.m.',\n",
              " 'p',\n",
              " 'pm',\n",
              " '11',\n",
              " '12',\n",
              " 'd',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8)',\n",
              " '8',\n",
              " 'd)',\n",
              " '8-)',\n",
              " 'd-)',\n",
              " '8-D',\n",
              " '8-d',\n",
              " 'd-X',\n",
              " '8D',\n",
              " '8d',\n",
              " 'dX',\n",
              " '9',\n",
              " \":'(\",\n",
              " \":')\",\n",
              " \":'-(\",\n",
              " \"'-(\",\n",
              " \":'-)\",\n",
              " \"'-)\",\n",
              " ':(',\n",
              " ':((',\n",
              " ':(((',\n",
              " '(((',\n",
              " ':()',\n",
              " ':)',\n",
              " ':))',\n",
              " ':)))',\n",
              " ')))',\n",
              " ':*',\n",
              " ':-(',\n",
              " ':-((',\n",
              " '-((',\n",
              " ':-(((',\n",
              " ':-)',\n",
              " ':-))',\n",
              " '-))',\n",
              " ':-)))',\n",
              " ':-*',\n",
              " ':-/',\n",
              " ':-0',\n",
              " ':-d',\n",
              " ':-3',\n",
              " ':->',\n",
              " ':-D',\n",
              " ':-X',\n",
              " ':-O',\n",
              " ':-o',\n",
              " ':-P',\n",
              " ':-p',\n",
              " ':-x',\n",
              " ':-]',\n",
              " ':-|',\n",
              " ':-}',\n",
              " ':/',\n",
              " ':0',\n",
              " ':d',\n",
              " ':1',\n",
              " ':3',\n",
              " ':>',\n",
              " ':D',\n",
              " ':X',\n",
              " ':O',\n",
              " ':o',\n",
              " ':P',\n",
              " ':p',\n",
              " ':x',\n",
              " ':]',\n",
              " ':o)',\n",
              " ':x)',\n",
              " ':|',\n",
              " ':}',\n",
              " ':’(',\n",
              " ':’)',\n",
              " ':’-(',\n",
              " '’-(',\n",
              " ':’-)',\n",
              " '’-)',\n",
              " ';)',\n",
              " ';',\n",
              " ';-)',\n",
              " ';-D',\n",
              " ';-d',\n",
              " ';-X',\n",
              " ';D',\n",
              " ';d',\n",
              " ';X',\n",
              " ';_;',\n",
              " '<.<',\n",
              " '<',\n",
              " '</3',\n",
              " '</d',\n",
              " '<3',\n",
              " '<d',\n",
              " '<33',\n",
              " '<dd',\n",
              " '<333',\n",
              " '333',\n",
              " '<ddd',\n",
              " '<space>',\n",
              " 'ce>',\n",
              " '<xxxx>',\n",
              " '=(',\n",
              " '=',\n",
              " '=)',\n",
              " '=/',\n",
              " '=3',\n",
              " '=d',\n",
              " '=D',\n",
              " '=X',\n",
              " '=|',\n",
              " '>.<',\n",
              " '>',\n",
              " '>.>',\n",
              " '>:(',\n",
              " '>:o',\n",
              " '>:x',\n",
              " '><(((*>',\n",
              " '(*>',\n",
              " '@_@',\n",
              " '@',\n",
              " 'Adm.',\n",
              " 'adm.',\n",
              " 'A',\n",
              " 'dm.',\n",
              " 'Xxx.',\n",
              " 'Ai',\n",
              " 'ai',\n",
              " 'Xx',\n",
              " 'n',\n",
              " \"x'x\",\n",
              " 'x’x',\n",
              " 'Ak.',\n",
              " 'Alaska',\n",
              " 'ak.',\n",
              " 'Xx.',\n",
              " 'Ala.',\n",
              " 'Alabama',\n",
              " 'ala.',\n",
              " 'la.',\n",
              " 'Apr.',\n",
              " 'April',\n",
              " 'apr.',\n",
              " 'pr.',\n",
              " 'Xxx',\n",
              " 'Ariz.',\n",
              " 'Arizona',\n",
              " 'ariz.',\n",
              " 'iz.',\n",
              " 'Xxxx.',\n",
              " 'Ark.',\n",
              " 'Arkansas',\n",
              " 'ark.',\n",
              " 'rk.',\n",
              " 'Aug.',\n",
              " 'August',\n",
              " 'aug.',\n",
              " 'ug.',\n",
              " 'Bros.',\n",
              " 'bros.',\n",
              " 'B',\n",
              " 'os.',\n",
              " 'C++',\n",
              " 'c++',\n",
              " 'C',\n",
              " 'X++',\n",
              " 'Calif.',\n",
              " 'California',\n",
              " 'calif.',\n",
              " 'if.',\n",
              " 'Xxxxx.',\n",
              " 'Ca',\n",
              " 'can',\n",
              " 'ca',\n",
              " 'Can',\n",
              " 'xxx',\n",
              " 've',\n",
              " 'v',\n",
              " '’ve',\n",
              " '’',\n",
              " '’xx',\n",
              " 'Co.',\n",
              " 'co.',\n",
              " 'Colo.',\n",
              " 'Colorado',\n",
              " 'colo.',\n",
              " 'lo.',\n",
              " 'Conn.',\n",
              " 'Connecticut',\n",
              " 'conn.',\n",
              " 'nn.',\n",
              " 'Corp.',\n",
              " 'corp.',\n",
              " 'rp.',\n",
              " 'Could',\n",
              " 'could',\n",
              " 'uld',\n",
              " 'Xxxxx',\n",
              " 'D.C.',\n",
              " 'd.c.',\n",
              " 'D',\n",
              " '.C.',\n",
              " 'X.X.',\n",
              " 'Dare',\n",
              " 'dare',\n",
              " 'Xxxx',\n",
              " 'Dec.',\n",
              " 'December',\n",
              " 'dec.',\n",
              " 'ec.',\n",
              " 'Del.',\n",
              " 'Delaware',\n",
              " 'del.',\n",
              " 'el.',\n",
              " 'oes',\n",
              " 'Doin',\n",
              " 'doing',\n",
              " 'doin',\n",
              " 'oin',\n",
              " \"Doin'\",\n",
              " \"doin'\",\n",
              " \"in'\",\n",
              " \"Xxxx'\",\n",
              " 'Doin’',\n",
              " 'doin’',\n",
              " 'in’',\n",
              " 'Xxxx’',\n",
              " 'Dr.',\n",
              " 'dr.',\n",
              " 'E.G.',\n",
              " 'e.g.',\n",
              " 'E',\n",
              " '.G.',\n",
              " 'E.g.',\n",
              " '.g.',\n",
              " 'X.x.',\n",
              " 'Feb.',\n",
              " 'February',\n",
              " 'feb.',\n",
              " 'F',\n",
              " 'eb.',\n",
              " 'Fla.',\n",
              " 'Florida',\n",
              " 'fla.',\n",
              " 'Ga.',\n",
              " 'Georgia',\n",
              " 'ga.',\n",
              " 'G',\n",
              " 'Gen.',\n",
              " 'gen.',\n",
              " 'en.',\n",
              " 'Goin',\n",
              " 'go',\n",
              " 'going',\n",
              " 'goin',\n",
              " \"Goin'\",\n",
              " \"goin'\",\n",
              " 'Goin’',\n",
              " 'goin’',\n",
              " 'Gon',\n",
              " 'gon',\n",
              " 'na',\n",
              " 'to',\n",
              " 'Got',\n",
              " 'got',\n",
              " 'ta',\n",
              " 't',\n",
              " 'Gov.',\n",
              " 'gov.',\n",
              " 'ov.',\n",
              " 'H',\n",
              " 'ave',\n",
              " 'Havin',\n",
              " 'having',\n",
              " 'havin',\n",
              " 'vin',\n",
              " \"Havin'\",\n",
              " \"havin'\",\n",
              " \"Xxxxx'\",\n",
              " 'Havin’',\n",
              " 'havin’',\n",
              " 'Xxxxx’',\n",
              " 'would',\n",
              " 'x',\n",
              " 'll',\n",
              " 'l',\n",
              " 's',\n",
              " '’d',\n",
              " '’x',\n",
              " '’ll',\n",
              " '’s',\n",
              " 'How',\n",
              " 'how',\n",
              " \"'y\",\n",
              " 're',\n",
              " 'r',\n",
              " '’y',\n",
              " '’re',\n",
              " 'i',\n",
              " 'going to',\n",
              " 'gonna',\n",
              " 'I.E.',\n",
              " 'i.e.',\n",
              " '.E.',\n",
              " 'I.e.',\n",
              " '.e.',\n",
              " 'Ia.',\n",
              " 'Iowa',\n",
              " 'ia.',\n",
              " 'Id.',\n",
              " 'Idaho',\n",
              " 'id.',\n",
              " 'Ill.',\n",
              " 'Illinois',\n",
              " 'ill.',\n",
              " 'll.',\n",
              " 'm',\n",
              " 'Inc.',\n",
              " 'inc.',\n",
              " 'nc.',\n",
              " 'Ind.',\n",
              " 'Indiana',\n",
              " 'ind.',\n",
              " 'nd.',\n",
              " '’m',\n",
              " 'Jan.',\n",
              " 'January',\n",
              " 'jan.',\n",
              " 'J',\n",
              " 'an.',\n",
              " 'Jr.',\n",
              " 'jr.',\n",
              " 'Jul.',\n",
              " 'July',\n",
              " 'jul.',\n",
              " 'ul.',\n",
              " 'Jun.',\n",
              " 'June',\n",
              " 'jun.',\n",
              " 'un.',\n",
              " 'Kan.',\n",
              " 'Kansas',\n",
              " 'kan.',\n",
              " 'K',\n",
              " 'Kans.',\n",
              " 'kans.',\n",
              " 'ns.',\n",
              " 'Ky.',\n",
              " 'Kentucky',\n",
              " 'ky.',\n",
              " 'La.',\n",
              " 'Louisiana',\n",
              " 'L',\n",
              " 'Let',\n",
              " 'let',\n",
              " 'Lovin',\n",
              " 'love',\n",
              " 'loving',\n",
              " 'lovin',\n",
              " \"Lovin'\",\n",
              " \"lovin'\",\n",
              " 'Lovin’',\n",
              " 'lovin’',\n",
              " 'Ltd.',\n",
              " 'ltd.',\n",
              " 'td.',\n",
              " \"Ma'am\",\n",
              " 'madam',\n",
              " \"ma'am\",\n",
              " 'M',\n",
              " \"'am\",\n",
              " \"Xx'xx\",\n",
              " 'Mar.',\n",
              " 'March',\n",
              " 'mar.',\n",
              " 'ar.',\n",
              " 'Mass.',\n",
              " 'Massachusetts',\n",
              " 'mass.',\n",
              " 'ss.',\n",
              " 'May.',\n",
              " 'May',\n",
              " 'may.',\n",
              " 'ay.',\n",
              " 'may',\n",
              " 'Ma’am',\n",
              " 'ma’am',\n",
              " '’am',\n",
              " 'Xx’xx',\n",
              " 'Md.',\n",
              " 'md.',\n",
              " 'Messrs.',\n",
              " 'messrs.',\n",
              " 'rs.',\n",
              " 'Mich.',\n",
              " 'Michigan',\n",
              " 'mich.',\n",
              " 'ch.',\n",
              " 'Might',\n",
              " 'might',\n",
              " 'ght',\n",
              " 'Minn.',\n",
              " 'Minnesota',\n",
              " 'minn.',\n",
              " 'Miss.',\n",
              " 'Mississippi',\n",
              " 'miss.',\n",
              " 'Mo.',\n",
              " 'mo.',\n",
              " 'Mont.',\n",
              " 'mont.',\n",
              " 'nt.',\n",
              " 'Mr.',\n",
              " 'mr.',\n",
              " 'Mrs.',\n",
              " 'mrs.',\n",
              " 'Ms.',\n",
              " 'ms.',\n",
              " 'Mt.',\n",
              " 'Mount',\n",
              " 'mt.',\n",
              " 'Must',\n",
              " 'must',\n",
              " 'ust',\n",
              " 'N.C.',\n",
              " 'North Carolina',\n",
              " 'n.c.',\n",
              " 'N',\n",
              " 'N.D.',\n",
              " 'North Dakota',\n",
              " 'n.d.',\n",
              " '.D.',\n",
              " 'N.H.',\n",
              " 'New Hampshire',\n",
              " 'n.h.',\n",
              " '.H.',\n",
              " 'N.J.',\n",
              " 'New Jersey',\n",
              " 'n.j.',\n",
              " '.J.',\n",
              " 'N.M.',\n",
              " 'New Mexico',\n",
              " 'n.m.',\n",
              " '.M.',\n",
              " 'N.Y.',\n",
              " 'New York',\n",
              " 'n.y.',\n",
              " '.Y.',\n",
              " 'Neb.',\n",
              " 'Nebraska',\n",
              " 'neb.',\n",
              " 'Nebr.',\n",
              " 'nebr.',\n",
              " 'br.',\n",
              " 'Need',\n",
              " 'need',\n",
              " 'eed',\n",
              " 'Nev.',\n",
              " 'Nevada',\n",
              " 'nev.',\n",
              " 'ev.',\n",
              " 'Nothin',\n",
              " 'nothin',\n",
              " 'hin',\n",
              " \"Nothin'\",\n",
              " \"nothin'\",\n",
              " 'Nothin’',\n",
              " 'nothin’',\n",
              " 'Nov.',\n",
              " 'November',\n",
              " 'nov.',\n",
              " 'Nuthin',\n",
              " 'nuthin',\n",
              " \"Nuthin'\",\n",
              " \"nuthin'\",\n",
              " 'Nuthin’',\n",
              " 'nuthin’',\n",
              " \"O'clock\",\n",
              " \"o'clock\",\n",
              " 'O',\n",
              " 'ock',\n",
              " \"X'xxxx\",\n",
              " 'O.O',\n",
              " 'o.o',\n",
              " 'X.X',\n",
              " 'O.o',\n",
              " 'X.x',\n",
              " 'O_O',\n",
              " 'o_o',\n",
              " 'X_X',\n",
              " 'O_o',\n",
              " 'X_x',\n",
              " 'Oct.',\n",
              " 'October',\n",
              " 'oct.',\n",
              " 'ct.',\n",
              " 'Okla.',\n",
              " 'Oklahoma',\n",
              " 'okla.',\n",
              " 'Ol',\n",
              " 'old',\n",
              " 'ol',\n",
              " \"Ol'\",\n",
              " \"ol'\",\n",
              " \"Xx'\",\n",
              " 'Ol’',\n",
              " 'ol’',\n",
              " 'Xx’',\n",
              " 'Ore.',\n",
              " 'Oregon',\n",
              " 'ore.',\n",
              " 're.',\n",
              " 'Ought',\n",
              " 'ought',\n",
              " 'O’clock',\n",
              " 'o’clock',\n",
              " 'X’xxxx',\n",
              " 'Pa.',\n",
              " 'Pennsylvania',\n",
              " 'pa.',\n",
              " 'P',\n",
              " 'Ph.D.',\n",
              " 'ph.d.',\n",
              " 'Xx.X.',\n",
              " 'Prof.',\n",
              " 'prof.',\n",
              " 'of.',\n",
              " 'Rep.',\n",
              " 'rep.',\n",
              " 'R',\n",
              " 'ep.',\n",
              " 'Rev.',\n",
              " 'rev.',\n",
              " 'S.C.',\n",
              " 'South Carolina',\n",
              " 's.c.',\n",
              " 'S',\n",
              " 'Sen.',\n",
              " 'sen.',\n",
              " 'Sep.',\n",
              " 'September',\n",
              " 'sep.',\n",
              " 'Sept.',\n",
              " 'sept.',\n",
              " 'pt.',\n",
              " 'Sha',\n",
              " 'shall',\n",
              " 'sha',\n",
              " 'Should',\n",
              " 'should',\n",
              " 'Somethin',\n",
              " 'somethin',\n",
              " \"Somethin'\",\n",
              " \"somethin'\",\n",
              " 'Somethin’',\n",
              " 'somethin’',\n",
              " 'St.',\n",
              " 'st.',\n",
              " 'Tenn.',\n",
              " 'Tennessee',\n",
              " 'tenn.',\n",
              " 'T',\n",
              " 'hat',\n",
              " 'There',\n",
              " 'there',\n",
              " 'ere',\n",
              " 'hey',\n",
              " 'V.V',\n",
              " 'v.v',\n",
              " 'V',\n",
              " 'V_V',\n",
              " 'v_v',\n",
              " 'Va.',\n",
              " 'Virginia',\n",
              " 'va.',\n",
              " 'Wash.',\n",
              " 'Washington',\n",
              " 'wash.',\n",
              " 'W',\n",
              " 'sh.',\n",
              " 'What',\n",
              " 'what',\n",
              " 'When',\n",
              " 'when',\n",
              " 'hen',\n",
              " 'Where',\n",
              " 'where',\n",
              " 'Who',\n",
              " 'who',\n",
              " 'Why',\n",
              " 'why',\n",
              " 'Wis.',\n",
              " 'Wisconsin',\n",
              " 'wis.',\n",
              " 'is.',\n",
              " 'Wo',\n",
              " 'wo',\n",
              " 'Would',\n",
              " 'XD',\n",
              " 'xd',\n",
              " 'XDD',\n",
              " 'xdd',\n",
              " 'XXX',\n",
              " 'Y',\n",
              " '[-:',\n",
              " '[',\n",
              " '[:',\n",
              " '\\\\\")',\n",
              " '\\\\',\n",
              " '\\\\n',\n",
              " '\\\\x',\n",
              " '\\\\t',\n",
              " '^_^',\n",
              " '^',\n",
              " '^__^',\n",
              " '__^',\n",
              " '^___^',\n",
              " 'a.',\n",
              " 'x.',\n",
              " 'and/or',\n",
              " '/or',\n",
              " 'xxx/xx',\n",
              " 'b.',\n",
              " 'b',\n",
              " 'c.',\n",
              " 'c',\n",
              " 'xxxx',\n",
              " 'xx.',\n",
              " 'd.',\n",
              " \"xxxx'\",\n",
              " 'xxxx’',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpNJRVxryMoj",
        "outputId": "0f175adc-525b-48eb-bdeb-b0427d071c2c"
      },
      "source": [
        "#Total number of words inside the largest Spacy model\n",
        "len(list(nlp.vocab.strings))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1476043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT8gcBh2ySza"
      },
      "source": [
        "#Lets take a look at an example and just start with a silly example\n",
        "word1=nlp('biology is a trip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ked0hFpez8ai",
        "outputId": "605d27d8-bf7d-49b0-96b4-18aa342404d7"
      },
      "source": [
        "#Nice thing about spacy is all the words have their associated 300-D vector derived from GLOVE\n",
        "word1.vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.31317517e-02,  1.20504759e-01, -4.07024249e-02,  8.44202489e-02,\n",
              "        3.36087495e-01,  6.80849999e-02, -2.08972007e-01, -1.59494251e-01,\n",
              "       -1.25278249e-01,  2.33912492e+00, -2.70556182e-01,  2.17035003e-02,\n",
              "        1.65440008e-01,  1.37907013e-01, -9.54304934e-02, -5.95849976e-02,\n",
              "       -3.40372473e-02,  1.39799249e+00,  7.71192536e-02, -5.75909913e-02,\n",
              "        1.27755105e-04, -1.76102489e-01, -1.68935001e-01,  3.18573058e-01,\n",
              "        1.38610512e-01,  1.20631747e-01,  2.13209003e-01, -4.28107530e-02,\n",
              "        9.54950005e-02,  3.05231273e-01, -2.12435499e-01, -3.57782543e-02,\n",
              "        3.47067982e-01, -3.96007597e-02,  3.00424919e-02,  1.61610752e-01,\n",
              "        3.88059735e-01, -9.85299945e-02, -1.13179594e-01, -3.00917506e-01,\n",
              "        1.88702494e-01,  1.08472504e-01,  3.13305035e-02, -6.10624962e-02,\n",
              "        1.46207005e-01,  1.27699494e-01, -1.32664248e-01, -1.47831991e-01,\n",
              "        1.14512511e-01, -6.89775050e-02, -1.43774003e-01,  1.83097005e-01,\n",
              "        2.15907514e-01,  1.53557509e-02,  1.31044984e-02, -2.41502523e-02,\n",
              "        1.44759998e-01,  2.21152529e-02,  1.31235003e-01, -1.53942510e-01,\n",
              "        1.25887945e-01,  2.41829500e-01, -1.20224915e-02,  3.71667519e-02,\n",
              "       -1.04999989e-02, -4.05584991e-01, -2.93052495e-01,  2.03728005e-01,\n",
              "       -1.52281255e-01,  1.62230998e-01, -1.03372492e-01, -1.49800032e-02,\n",
              "       -1.58349991e-01,  1.93085000e-02, -1.71665251e-01,  1.68559980e-02,\n",
              "       -5.25990017e-02,  9.05427486e-02, -2.19577506e-01,  2.86216766e-01,\n",
              "       -2.02324986e-02, -7.68987462e-02,  1.95444264e-02,  9.34910923e-02,\n",
              "        1.37765005e-01, -3.78202021e-01, -3.08140248e-01, -1.78775005e-02,\n",
              "        2.39450037e-02, -4.74049971e-02, -1.74187243e-01,  4.17679995e-01,\n",
              "       -1.49333552e-01, -1.06608249e-01, -7.39414990e-02,  1.83204487e-01,\n",
              "        2.35600024e-03,  3.23577523e-02,  1.97427511e-01,  3.26977491e-01,\n",
              "       -2.90824920e-02, -1.23887494e-01, -4.33975086e-02, -1.02152497e-01,\n",
              "        1.28402755e-01, -6.63518488e-01,  6.78747594e-02,  1.41389251e-01,\n",
              "        1.13611750e-01, -1.09441027e-01,  1.75810009e-01, -3.17940116e-02,\n",
              "       -1.15134254e-01, -8.21169913e-02, -8.73517469e-02,  3.87124717e-03,\n",
              "       -1.02999806e-03,  1.77719995e-01,  6.70574978e-02,  9.69635025e-02,\n",
              "        1.86774917e-02, -1.20396510e-01,  8.09562355e-02, -1.65933013e-01,\n",
              "       -5.84140010e-02,  4.09487486e-01, -1.62851751e-01, -8.43174905e-02,\n",
              "        4.00256254e-02,  7.51724988e-02, -6.98107481e-02, -7.66957477e-02,\n",
              "       -9.26027447e-02,  2.24746749e-01,  9.65202749e-02, -2.28398860e-01,\n",
              "       -1.63212493e-01, -3.82745005e-02,  6.22302592e-02, -5.75402491e-02,\n",
              "       -8.96002769e-01,  1.34174243e-01,  1.71844497e-01,  2.24752471e-01,\n",
              "        7.22232461e-02, -2.05687493e-01, -3.11105996e-01, -1.56805247e-01,\n",
              "        1.97227508e-01,  2.99402587e-02, -1.35535628e-01, -4.70549949e-02,\n",
              "       -9.26098973e-03,  5.55842444e-02,  9.03620012e-03,  1.09871000e-01,\n",
              "       -3.52767557e-02, -2.24595010e-01,  3.41764949e-02, -1.44361272e-01,\n",
              "        2.27582499e-01, -1.64330989e-01, -7.06337467e-02, -1.24429002e-01,\n",
              "        6.67599961e-02,  5.06275073e-02,  4.61424887e-03,  2.72024982e-02,\n",
              "        2.51306772e-01,  4.91500050e-02,  9.27712470e-02, -1.23400148e-03,\n",
              "        3.08918983e-01, -3.59022543e-02, -1.47731006e-01, -1.09223500e-01,\n",
              "        4.35767472e-02, -2.18038499e-01,  7.60724992e-02, -3.04329973e-02,\n",
              "        1.66749991e-02, -1.20502502e-01, -6.72047511e-02,  2.66499072e-03,\n",
              "        1.84282005e-01, -1.95724398e-01, -3.41389962e-02,  9.79532450e-02,\n",
              "       -1.20793745e-01, -1.56699866e-03, -1.53705001e-01, -5.34327477e-02,\n",
              "       -3.18407506e-01,  1.72192499e-01, -9.13000107e-03,  2.18602508e-01,\n",
              "        7.28254989e-02, -2.55817547e-02,  2.31215239e-01, -1.00578003e-01,\n",
              "       -2.46997252e-01,  3.41349989e-02, -3.11185002e-01,  1.49762243e-01,\n",
              "        2.44161755e-01, -1.54340982e-01,  1.12844497e-01,  1.44856498e-01,\n",
              "        2.07857504e-01,  6.97542503e-02, -2.03852490e-01,  2.28997469e-02,\n",
              "        4.45685051e-02, -3.62809986e-01,  3.19399983e-02,  2.14170009e-01,\n",
              "       -4.63249981e-02,  2.71297514e-01, -3.63272503e-02,  4.63130027e-02,\n",
              "       -1.17329754e-01, -1.43048257e-01, -1.07520506e-01, -1.78869992e-01,\n",
              "        1.01849996e-02, -6.74899966e-02, -2.20570024e-02,  2.60138750e-01,\n",
              "        6.50398433e-03,  2.86867738e-01, -1.29200011e-01,  1.05899245e-01,\n",
              "        7.05324933e-02, -9.66285020e-02, -2.39855751e-01, -7.27637410e-02,\n",
              "       -1.15862504e-01,  5.73100001e-02, -1.17020257e-01,  4.36397493e-01,\n",
              "       -7.67424935e-03, -6.99725002e-02, -2.57224999e-02,  1.79425254e-01,\n",
              "        8.66032541e-02, -9.59257632e-02, -1.32525012e-01, -2.08743483e-01,\n",
              "        9.01883915e-02, -8.25754926e-02, -3.09232492e-02, -2.95736492e-01,\n",
              "        6.80852532e-02,  1.20615065e-02,  2.00814232e-01, -5.23552448e-02,\n",
              "        3.29814330e-02, -3.28687489e-01,  1.25576228e-01, -3.05412561e-02,\n",
              "        6.67774491e-03,  2.56402761e-01,  5.21347485e-02, -7.84920007e-02,\n",
              "        3.37315261e-01, -1.33155003e-01,  8.28375481e-03,  8.79488960e-02,\n",
              "        2.52674997e-01,  2.32775249e-02, -2.58628249e-01, -2.75605060e-02,\n",
              "       -7.95505047e-02, -1.43458009e-01, -1.67625025e-03,  2.18906999e-01,\n",
              "       -8.33355039e-02, -2.31752545e-02,  2.29724981e-02,  7.17285052e-02,\n",
              "        2.91495025e-01,  1.01174414e-03, -1.37461483e-01, -2.95692459e-02,\n",
              "       -2.23093748e-01, -1.93222761e-01, -1.43190008e-02, -2.05588251e-01,\n",
              "        2.53449939e-03,  8.60517472e-02,  1.74190745e-01,  8.80580992e-02,\n",
              "        9.14785173e-03, -1.75947502e-01,  2.58355498e-01,  1.95856735e-01,\n",
              "       -7.76118711e-02,  1.01697505e-01, -2.23932505e-01, -9.74418223e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP-by443w4Ab",
        "outputId": "b878275f-88f3-48e9-cb36-97328c897bfa"
      },
      "source": [
        "#Just confirming that its a 300-D vector\n",
        "word1.vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f05148Npz9g9",
        "outputId": "ac4f28ca-372d-498d-ed5b-b3a2dd743dce"
      },
      "source": [
        "#Lets test its similarity to various words - this one should be close to zero\n",
        "word2=nlp('hockey')\n",
        "word1.similarity(word2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27706726569459217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbT9w44q0PQw",
        "outputId": "e9818159-5f3a-406e-e88d-ed4601e42729"
      },
      "source": [
        "#This value should be closer to 1\n",
        "word3=nlp('cardiology')\n",
        "word1.similarity(word3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18761259681641534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "566HEgaG0UOG",
        "outputId": "7b46cebb-1925-4294-f610-2de48a5cca29"
      },
      "source": [
        "#This should be even closer to 1\n",
        "word4=nlp('pathology')\n",
        "word1.similarity(word4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3716108163236404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMZR07be5x4K"
      },
      "source": [
        "#Create a function, drawing on Spacy's similarity function, to identify words with the highest cosine similarity to the word of interest\n",
        "def top_word_similarities(word,number):\n",
        "  word_of_interest=nlp(word)\n",
        "  loop1=[w for w in nlp.vocab if np.count_nonzero(w.vector) and w.is_lower] #Turn our vocab into a list of lower case and nonzero vectors\n",
        "  sorted_similarities = sorted(loop1, key=lambda w: word_of_interest.similarity(w), reverse=True)\n",
        "  x=[(w.text,w.similarity(word_of_interest)) for w in sorted_similarities[:number+1]]\n",
        "  return pd.DataFrame(x, columns =['Word', 'Similarity Score']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "Y7K2Lmc48rAZ",
        "outputId": "175c1311-3300-4c84-d3d0-b25cf46fe67e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "top_word_similarities('happiness',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>happiness</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>joy</td>\n",
              "      <td>0.775831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contentment</td>\n",
              "      <td>0.772960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bliss</td>\n",
              "      <td>0.674258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>prosperity</td>\n",
              "      <td>0.662932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gratitude</td>\n",
              "      <td>0.657593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>well-being</td>\n",
              "      <td>0.647229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sadness</td>\n",
              "      <td>0.647188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>feelings</td>\n",
              "      <td>0.640027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>life</td>\n",
              "      <td>0.639290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>desire</td>\n",
              "      <td>0.618441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>compassion</td>\n",
              "      <td>0.617214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendship</td>\n",
              "      <td>0.607219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>dreams</td>\n",
              "      <td>0.606784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>enjoyment</td>\n",
              "      <td>0.605159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>loneliness</td>\n",
              "      <td>0.604061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>laughter</td>\n",
              "      <td>0.603583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>emotions</td>\n",
              "      <td>0.602578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>kindness</td>\n",
              "      <td>0.600794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>blessings</td>\n",
              "      <td>0.598542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>eternal</td>\n",
              "      <td>0.597215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>despair</td>\n",
              "      <td>0.593826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>joyful</td>\n",
              "      <td>0.593786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>unhappiness</td>\n",
              "      <td>0.593459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>enlightenment</td>\n",
              "      <td>0.592581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sorrow</td>\n",
              "      <td>0.587698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Word  Similarity Score\n",
              "0       happiness          1.000000\n",
              "1             joy          0.775831\n",
              "2     contentment          0.772960\n",
              "3           bliss          0.674258\n",
              "4      prosperity          0.662932\n",
              "5       gratitude          0.657593\n",
              "6      well-being          0.647229\n",
              "7         sadness          0.647188\n",
              "8        feelings          0.640027\n",
              "9            life          0.639290\n",
              "10         desire          0.618441\n",
              "11     compassion          0.617214\n",
              "12     friendship          0.607219\n",
              "13         dreams          0.606784\n",
              "14      enjoyment          0.605159\n",
              "15     loneliness          0.604061\n",
              "16       laughter          0.603583\n",
              "17       emotions          0.602578\n",
              "18       kindness          0.600794\n",
              "19      blessings          0.598542\n",
              "20        eternal          0.597215\n",
              "21        despair          0.593826\n",
              "22         joyful          0.593786\n",
              "23    unhappiness          0.593459\n",
              "24  enlightenment          0.592581\n",
              "25         sorrow          0.587698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "02IjE9SF8uiv",
        "outputId": "b50c3d23-545b-4754-9169-f0fc535b53a7"
      },
      "source": [
        "\n",
        "top_word_similarities('make an address',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>an</td>\n",
              "      <td>0.774153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>make</td>\n",
              "      <td>0.766196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>address</td>\n",
              "      <td>0.757614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one</td>\n",
              "      <td>0.719507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to</td>\n",
              "      <td>0.716454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>any</td>\n",
              "      <td>0.709064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>can</td>\n",
              "      <td>0.707185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>that</td>\n",
              "      <td>0.706303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>way</td>\n",
              "      <td>0.704445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>if</td>\n",
              "      <td>0.702876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>be</td>\n",
              "      <td>0.701879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>another</td>\n",
              "      <td>0.691734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>you</td>\n",
              "      <td>0.686603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>it</td>\n",
              "      <td>0.684715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>give</td>\n",
              "      <td>0.683150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>will</td>\n",
              "      <td>0.682957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>need</td>\n",
              "      <td>0.682928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>able</td>\n",
              "      <td>0.677627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>would</td>\n",
              "      <td>0.677028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>possible</td>\n",
              "      <td>0.676851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>not</td>\n",
              "      <td>0.676579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>should</td>\n",
              "      <td>0.675114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>either</td>\n",
              "      <td>0.667844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>could</td>\n",
              "      <td>0.667086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>simply</td>\n",
              "      <td>0.665739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>whether</td>\n",
              "      <td>0.664083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Word  Similarity Score\n",
              "0         an          0.774153\n",
              "1       make          0.766196\n",
              "2    address          0.757614\n",
              "3        one          0.719507\n",
              "4         to          0.716454\n",
              "5        any          0.709064\n",
              "6        can          0.707185\n",
              "7       that          0.706303\n",
              "8        way          0.704445\n",
              "9         if          0.702876\n",
              "10        be          0.701879\n",
              "11   another          0.691734\n",
              "12       you          0.686603\n",
              "13        it          0.684715\n",
              "14      give          0.683150\n",
              "15      will          0.682957\n",
              "16      need          0.682928\n",
              "17      able          0.677627\n",
              "18     would          0.677028\n",
              "19  possible          0.676851\n",
              "20       not          0.676579\n",
              "21    should          0.675114\n",
              "22    either          0.667844\n",
              "23     could          0.667086\n",
              "24    simply          0.665739\n",
              "25   whether          0.664083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "Ul9hxixue92P",
        "outputId": "48e0d5d4-7972-4d8b-98e9-fe058070b1e1"
      },
      "source": [
        "top_word_similarities('go to address',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>to</td>\n",
              "      <td>0.855064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go</td>\n",
              "      <td>0.807855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>address</td>\n",
              "      <td>0.773133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>can</td>\n",
              "      <td>0.725248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>want</td>\n",
              "      <td>0.723591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>going</td>\n",
              "      <td>0.719682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you</td>\n",
              "      <td>0.717470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>able</td>\n",
              "      <td>0.716351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>way</td>\n",
              "      <td>0.715895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>get</td>\n",
              "      <td>0.712287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>will</td>\n",
              "      <td>0.710883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>need</td>\n",
              "      <td>0.710191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>let</td>\n",
              "      <td>0.704903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>take</td>\n",
              "      <td>0.703040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>make</td>\n",
              "      <td>0.695660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>should</td>\n",
              "      <td>0.693634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>them</td>\n",
              "      <td>0.692526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>would</td>\n",
              "      <td>0.689069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>if</td>\n",
              "      <td>0.688734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ask</td>\n",
              "      <td>0.684980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>could</td>\n",
              "      <td>0.682850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>'ll</td>\n",
              "      <td>0.682450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>us</td>\n",
              "      <td>0.681774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>leave</td>\n",
              "      <td>0.678964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>enter</td>\n",
              "      <td>0.675710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>send</td>\n",
              "      <td>0.675325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word  Similarity Score\n",
              "0        to          0.855064\n",
              "1        go          0.807855\n",
              "2   address          0.773133\n",
              "3       can          0.725248\n",
              "4      want          0.723591\n",
              "5     going          0.719682\n",
              "6       you          0.717470\n",
              "7      able          0.716351\n",
              "8       way          0.715895\n",
              "9       get          0.712287\n",
              "10     will          0.710883\n",
              "11     need          0.710191\n",
              "12      let          0.704903\n",
              "13     take          0.703040\n",
              "14     make          0.695660\n",
              "15   should          0.693634\n",
              "16     them          0.692526\n",
              "17    would          0.689069\n",
              "18       if          0.688734\n",
              "19      ask          0.684980\n",
              "20    could          0.682850\n",
              "21      'll          0.682450\n",
              "22       us          0.681774\n",
              "23    leave          0.678964\n",
              "24    enter          0.675710\n",
              "25     send          0.675325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "JMLsXLWrf71T",
        "outputId": "f12ebabf-96be-40e3-b1f6-3075d294129c"
      },
      "source": [
        "top_word_similarities('creativity',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>creativity</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>creative</td>\n",
              "      <td>0.800415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagination</td>\n",
              "      <td>0.759219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>originality</td>\n",
              "      <td>0.709184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>inspiration</td>\n",
              "      <td>0.702141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ingenuity</td>\n",
              "      <td>0.693314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>inventiveness</td>\n",
              "      <td>0.679081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>artistic</td>\n",
              "      <td>0.675066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>creativeness</td>\n",
              "      <td>0.671187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>innovation</td>\n",
              "      <td>0.664305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>passion</td>\n",
              "      <td>0.655068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>artistry</td>\n",
              "      <td>0.650408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>individuality</td>\n",
              "      <td>0.644738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>inspire</td>\n",
              "      <td>0.644143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>0.641415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>self-expression</td>\n",
              "      <td>0.639207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>spontaneity</td>\n",
              "      <td>0.629854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>imaginative</td>\n",
              "      <td>0.623330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>motivation</td>\n",
              "      <td>0.619925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>resourcefulness</td>\n",
              "      <td>0.605719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>teamwork</td>\n",
              "      <td>0.600952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>entrepreneurial</td>\n",
              "      <td>0.596992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>inspires</td>\n",
              "      <td>0.594341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>talents</td>\n",
              "      <td>0.593151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>storytelling</td>\n",
              "      <td>0.590511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>curiosity</td>\n",
              "      <td>0.589669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Word  Similarity Score\n",
              "0        creativity          1.000000\n",
              "1          creative          0.800415\n",
              "2       imagination          0.759219\n",
              "3       originality          0.709184\n",
              "4       inspiration          0.702141\n",
              "5         ingenuity          0.693314\n",
              "6     inventiveness          0.679081\n",
              "7          artistic          0.675066\n",
              "8      creativeness          0.671187\n",
              "9        innovation          0.664305\n",
              "10          passion          0.655068\n",
              "11         artistry          0.650408\n",
              "12    individuality          0.644738\n",
              "13          inspire          0.644143\n",
              "14       enthusiasm          0.641415\n",
              "15  self-expression          0.639207\n",
              "16      spontaneity          0.629854\n",
              "17      imaginative          0.623330\n",
              "18       motivation          0.619925\n",
              "19  resourcefulness          0.605719\n",
              "20         teamwork          0.600952\n",
              "21  entrepreneurial          0.596992\n",
              "22         inspires          0.594341\n",
              "23          talents          0.593151\n",
              "24     storytelling          0.590511\n",
              "25        curiosity          0.589669"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "NmJ00eBujhpX",
        "outputId": "e49fc551-7498-435e-f568-2dec319017e9"
      },
      "source": [
        "top_word_similarities('belonging',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>belonging</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>belonged</td>\n",
              "      <td>0.732935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>belong</td>\n",
              "      <td>0.698903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>belongs</td>\n",
              "      <td>0.632408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>namely</td>\n",
              "      <td>0.577809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>identified</td>\n",
              "      <td>0.518709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>residing</td>\n",
              "      <td>0.514203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>chiefly</td>\n",
              "      <td>0.512096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>occupied</td>\n",
              "      <td>0.504378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>representing</td>\n",
              "      <td>0.503079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>represented</td>\n",
              "      <td>0.493192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>distinct</td>\n",
              "      <td>0.492230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>neighbouring</td>\n",
              "      <td>0.491529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>persons</td>\n",
              "      <td>0.490823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>principally</td>\n",
              "      <td>0.488308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>constitute</td>\n",
              "      <td>0.488235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>possessed</td>\n",
              "      <td>0.482468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>whose</td>\n",
              "      <td>0.482239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>particular</td>\n",
              "      <td>0.480953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>constituted</td>\n",
              "      <td>0.479928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>reside</td>\n",
              "      <td>0.474481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>associated</td>\n",
              "      <td>0.474304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>deceased</td>\n",
              "      <td>0.473376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>identity</td>\n",
              "      <td>0.471670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>presumably</td>\n",
              "      <td>0.470365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>constituting</td>\n",
              "      <td>0.469781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Word  Similarity Score\n",
              "0      belonging          1.000000\n",
              "1       belonged          0.732935\n",
              "2         belong          0.698903\n",
              "3        belongs          0.632408\n",
              "4         namely          0.577809\n",
              "5     identified          0.518709\n",
              "6       residing          0.514203\n",
              "7        chiefly          0.512096\n",
              "8       occupied          0.504378\n",
              "9   representing          0.503079\n",
              "10   represented          0.493192\n",
              "11      distinct          0.492230\n",
              "12  neighbouring          0.491529\n",
              "13       persons          0.490823\n",
              "14   principally          0.488308\n",
              "15    constitute          0.488235\n",
              "16     possessed          0.482468\n",
              "17         whose          0.482239\n",
              "18    particular          0.480953\n",
              "19   constituted          0.479928\n",
              "20        reside          0.474481\n",
              "21    associated          0.474304\n",
              "22      deceased          0.473376\n",
              "23      identity          0.471670\n",
              "24    presumably          0.470365\n",
              "25  constituting          0.469781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "OHqhfeObjjlo",
        "outputId": "6f116d0e-da06-4140-da69-98125eac7ad1"
      },
      "source": [
        "top_word_similarities('human',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>human</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>humans</td>\n",
              "      <td>0.743876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>beings</td>\n",
              "      <td>0.707788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>humanity</td>\n",
              "      <td>0.686135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>animal</td>\n",
              "      <td>0.606420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>non-human</td>\n",
              "      <td>0.602825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>understanding</td>\n",
              "      <td>0.600429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>expression</td>\n",
              "      <td>0.597327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>biological</td>\n",
              "      <td>0.595458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>nature</td>\n",
              "      <td>0.578378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>genetic</td>\n",
              "      <td>0.577334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>animals</td>\n",
              "      <td>0.575584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>mankind</td>\n",
              "      <td>0.572377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>existence</td>\n",
              "      <td>0.569410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>society</td>\n",
              "      <td>0.562816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>brain</td>\n",
              "      <td>0.550821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>life</td>\n",
              "      <td>0.548001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>nonhuman</td>\n",
              "      <td>0.546936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>sense</td>\n",
              "      <td>0.545929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>innate</td>\n",
              "      <td>0.539690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>mammalian</td>\n",
              "      <td>0.539614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>evolution</td>\n",
              "      <td>0.534250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>organism</td>\n",
              "      <td>0.533602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>knowledge</td>\n",
              "      <td>0.532890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>humankind</td>\n",
              "      <td>0.529542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>consciousness</td>\n",
              "      <td>0.529191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Word  Similarity Score\n",
              "0           human          1.000000\n",
              "1          humans          0.743876\n",
              "2          beings          0.707788\n",
              "3        humanity          0.686135\n",
              "4          animal          0.606420\n",
              "5       non-human          0.602825\n",
              "6   understanding          0.600429\n",
              "7      expression          0.597327\n",
              "8      biological          0.595458\n",
              "9          nature          0.578378\n",
              "10        genetic          0.577334\n",
              "11        animals          0.575584\n",
              "12        mankind          0.572377\n",
              "13      existence          0.569410\n",
              "14        society          0.562816\n",
              "15          brain          0.550821\n",
              "16           life          0.548001\n",
              "17       nonhuman          0.546936\n",
              "18          sense          0.545929\n",
              "19         innate          0.539690\n",
              "20      mammalian          0.539614\n",
              "21      evolution          0.534250\n",
              "22       organism          0.533602\n",
              "23      knowledge          0.532890\n",
              "24      humankind          0.529542\n",
              "25  consciousness          0.529191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "Hcx9kV4Vjsiz",
        "outputId": "1d5ed700-7f39-423f-e0f3-4e02affc9d2d"
      },
      "source": [
        "top_word_similarities('wellbeing',number=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wellbeing</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>well-being</td>\n",
              "      <td>0.885165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wellness</td>\n",
              "      <td>0.724912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>health</td>\n",
              "      <td>0.662913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>healthiness</td>\n",
              "      <td>0.642032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>vitality</td>\n",
              "      <td>0.605635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>holistic</td>\n",
              "      <td>0.570561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mental</td>\n",
              "      <td>0.560888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>happiness</td>\n",
              "      <td>0.551501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>health-related</td>\n",
              "      <td>0.549534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>self-esteem</td>\n",
              "      <td>0.548449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lifestyle</td>\n",
              "      <td>0.547779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>healthful</td>\n",
              "      <td>0.543437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>empowerment</td>\n",
              "      <td>0.543219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>esteem</td>\n",
              "      <td>0.537995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>safeguarding</td>\n",
              "      <td>0.533723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>vital</td>\n",
              "      <td>0.532464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>betterment</td>\n",
              "      <td>0.528048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>healthy</td>\n",
              "      <td>0.527835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>self-care</td>\n",
              "      <td>0.517997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>lifestyles</td>\n",
              "      <td>0.512474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>life-style</td>\n",
              "      <td>0.511822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>healthier</td>\n",
              "      <td>0.511307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>workplace</td>\n",
              "      <td>0.510039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>improving</td>\n",
              "      <td>0.509268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>nutrition</td>\n",
              "      <td>0.508519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Word  Similarity Score\n",
              "0        wellbeing          1.000000\n",
              "1       well-being          0.885165\n",
              "2         wellness          0.724912\n",
              "3           health          0.662913\n",
              "4      healthiness          0.642032\n",
              "5         vitality          0.605635\n",
              "6         holistic          0.570561\n",
              "7           mental          0.560888\n",
              "8        happiness          0.551501\n",
              "9   health-related          0.549534\n",
              "10     self-esteem          0.548449\n",
              "11       lifestyle          0.547779\n",
              "12       healthful          0.543437\n",
              "13     empowerment          0.543219\n",
              "14          esteem          0.537995\n",
              "15    safeguarding          0.533723\n",
              "16           vital          0.532464\n",
              "17      betterment          0.528048\n",
              "18         healthy          0.527835\n",
              "19       self-care          0.517997\n",
              "20      lifestyles          0.512474\n",
              "21      life-style          0.511822\n",
              "22       healthier          0.511307\n",
              "23       workplace          0.510039\n",
              "24       improving          0.509268\n",
              "25       nutrition          0.508519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPIfSy6kj_Aw",
        "outputId": "4b5cc36f-7faa-4961-d1e9-a3f70409920e"
      },
      "source": [
        "word1=nlp('wellbeing')\n",
        "word2=nlp('nature')\n",
        "word1.similarity(word2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35062251192703564"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "q9065AEkJbru",
        "outputId": "7221f958-bcb4-4923-f7ae-be308b4bd837"
      },
      "source": [
        "x=top_word_similarities('nature',number=251)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1d556146c0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_word_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nature'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m251\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-22f92fddbfde>\u001b[0m in \u001b[0;36mtop_word_similarities\u001b[0;34m(word, number)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop_word_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mword_of_interest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mloop1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_lower\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Turn our vocab into a list of lower case and nonzero vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msorted_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_of_interest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_of_interest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_similarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-22f92fddbfde>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop_word_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mword_of_interest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mloop1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_lower\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Turn our vocab into a list of lower case and nonzero vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msorted_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_of_interest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_of_interest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_similarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlexeme.pyx\u001b[0m in \u001b[0;36mspacy.lexeme.Lexeme.vector.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/neural/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcupy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mget_array_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek0gGjkDyR2q"
      },
      "source": [
        "x2=top_word_similarities('environment',number=251)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlcKqn0fyuGz"
      },
      "source": [
        "x3=top_word_similarities('ecosystem',number=251)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK8Om3bEyxNE"
      },
      "source": [
        "x4=top_word_similarities('outdoors',number=251)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku6AsW5Ayzyc"
      },
      "source": [
        "x5=top_word_similarities('wellbeing',number=251)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg50RL3cy3WT"
      },
      "source": [
        "x6=pd.concat([x,x2,x3,x4,x5],axis=1)\n",
        "x6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIv22ZKpzR5I"
      },
      "source": [
        "x6.to_csv('/content/drive/My Drive/similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWkSMf0kzss8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "x7=top_word_similarities('ecology',number=251)\n",
        "x7.to_csv('/content/drive/My Drive/ecology_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjuX67XgOfQ0"
      },
      "source": [
        "top_word_similarities('ecology',number=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpC7mZWjtjgR"
      },
      "source": [
        "x8=top_word_similarities('family',number=251)\n",
        "x8.to_csv('/content/drive/My Drive/family_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5tCJy5Bt5pz"
      },
      "source": [
        "x9=top_word_similarities('money',number=251)\n",
        "x9.to_csv('/content/drive/My Drive/money_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUHLcX2-t89U"
      },
      "source": [
        "x10=top_word_similarities('love',number=251)\n",
        "x10.to_csv('/content/drive/My Drive/love_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7w2Pouat9So"
      },
      "source": [
        "x11=top_word_similarities('spirituality',number=251)\n",
        "x11.to_csv('/content/drive/My Drive/spirituality_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFLzQAXwuz0z"
      },
      "source": [
        "x11=top_word_similarities('police',number=301)\n",
        "x11.to_csv('/content/drive/My Drive/police_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgGPifBMF0H6"
      },
      "source": [
        "x12=top_word_similarities('brutality',number=301)\n",
        "x12.to_csv('/content/drive/My Drive/brutality_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaJhq9EEF0cx"
      },
      "source": [
        "x13=top_word_similarities('hate',number=301)\n",
        "x13.to_csv('/content/drive/My Drive/hate_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYn0CKCwF0yK"
      },
      "source": [
        "x14=top_word_similarities('crime',number=301)\n",
        "x14.to_csv('/content/drive/My Drive/crime_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqRsJNQbF1HF"
      },
      "source": [
        "x19=top_word_similarities('arrest',number=301)\n",
        "x19.to_csv('/content/drive/My Drive/arrest_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fKNVk-lF1hu"
      },
      "source": [
        "x20=top_word_similarities('mental health',number=301)\n",
        "x20.to_csv('/content/drive/My Drive/mentalhealth_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC26A_gOF127"
      },
      "source": [
        "x21=top_word_similarities('arrest report',number=301)\n",
        "x21.to_csv('/content/drive/My Drive/arrestreport_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uikYl-4xHdld"
      },
      "source": [
        "x22=top_word_similarities('african american',number=301)\n",
        "x22.to_csv('/content/drive/My Drive/africanamerican_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v6LbGOBIqkL"
      },
      "source": [
        "x23=top_word_similarities('black',number=301)\n",
        "x23.to_csv('/content/drive/My Drive/black_similarity_scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ZOVSG5m9Bd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}